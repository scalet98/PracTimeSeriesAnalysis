{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315395db",
   "metadata": {},
   "source": [
    "## CH10_2_Dip-learning for Timeseries \n",
    "\n",
    "- Last update : 2022.05.11."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe2fe63",
   "metadata": {},
   "source": [
    "## 의사코드 \n",
    "- symbol A; \n",
    "- symbol B; \n",
    "- symbol C = matmul(A, B); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "689f0203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Wed_Oct_23_19:32:27_Pacific_Daylight_Time_2019\n",
      "Cuda compilation tools, release 10.2, V10.2.89\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d9ac854",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(None -> 120, Activation(relu))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MXNET : completelly connected Object \n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "fc1 = mx.gluon.nn.Dense(120, activation = 'relu')\n",
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ee21d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple diplearning code \n",
    "## >>> input, target, loss definition, category allocation in model \n",
    "\n",
    "## Generating neural network model instead of defining independet levels solely\n",
    "## ref :  https://mxnet.apache.org/versions/1.7/api/python/docs/tutorials/packages/gluon/blocks/init.html\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import init, nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(120, activation= 'relu'), nn.Dense(1))\n",
    "net.initialize(init=init.Xavier())\n",
    "\n",
    "## Defining wanted loss \n",
    "L2Loss = mx.gluon.loss.L2Loss()\n",
    "\n",
    "trainer = mx.gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68cfe034",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10564/2016240043.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m## which means (all the dataset is go through with the neural network)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m## calculating slope\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "## Based on the assumption that all the required dataset has been designed, \n",
    "## below codes proceed the learning epoch\n",
    "## which means (all the dataset is go through with the neural network)\n",
    "\n",
    "for data, target in train_data: \n",
    "    ## calculating slope \n",
    "    with autograd.record():\n",
    "        out = net(data)\n",
    "        loss = L2Loss(output, data)\n",
    "    loss.backward()\n",
    "    ## applying slope to update parameters \n",
    "trainer.step(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4662f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_py37",
   "language": "python",
   "name": "tf_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
